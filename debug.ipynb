{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\vits\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import model\n",
    "from crypko_data import crypkoFace as cy\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(object):\n",
    "    def __init__(self, init_channel=100, batchsize=64, lr=1e-4, max_epoch=10, params_range=0.01, distraintimes=5):\n",
    "        #models\n",
    "        self.G=model.generator(init_channel).cuda()\n",
    "        self.D=model.discriminator().cuda()\n",
    "        #hyperparameters\n",
    "        self.init_channel = init_channel\n",
    "        self.batch_size = batchsize\n",
    "        self.lr = lr\n",
    "        self.max_epoch = max_epoch\n",
    "        self.diss_train_times=distraintimes\n",
    "        self.params_range=params_range\n",
    "        #optmizer\n",
    "        self.gen_opt=torch.optim.RMSprop(self.G.parameters(), lr=self.lr)\n",
    "        self.dis_opt=torch.optim.RMSprop(self.D.parameters(), lr=self.lr)\n",
    "        #dataloader\n",
    "        dataset=cy()\n",
    "        self.dataloader=DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    def train(self):\n",
    "        #turning models into training mode\n",
    "        self.G.train()\n",
    "        self.D.train()\n",
    "\n",
    "        check_noise = Variable(torch.randn(100, self.init_channel, 1, 1)).cuda(non_blocking=True)\n",
    "        \n",
    "        #training start\n",
    "        for e in range(self.max_epoch):\n",
    "            w_loss=[]\n",
    "\n",
    "            def main():\n",
    "                for i,data in enumerate(tqdm(self.dataloader),0):\n",
    "                    #prepare real data and fake data\n",
    "                    real_raw=data.cuda(non_blocking=True)\n",
    "                    real = Variable(real_raw).cuda(non_blocking=True)\n",
    "\n",
    "                    noise=Variable(torch.randn(self.batch_size, self.init_channel, 1, 1)).cuda(non_blocking=True)\n",
    "                    fake=self.G(noise).cuda(non_blocking=True)\n",
    "\n",
    "                    #train the discriminator for several times\n",
    "                    #enable the gradcomputation of discriminator\n",
    "                    for p in self.D.parameters():\n",
    "                        p.requires_grad=True\n",
    "                    for j in range(self.diss_train_times):\n",
    "                        #clipping\n",
    "                        for p in self.D.parameters():\n",
    "                            p=torch.clamp_(p, min=-self.params_range, max=self.params_range)\n",
    "                        #neutralize the gradients\n",
    "                        self.D.zero_grad()\n",
    "                        #discriminate\n",
    "                        real_dis=self.D(real.detach())\n",
    "                        fake_dis=self.D(fake.detach())\n",
    "                        #compute the loss\n",
    "                        real_loss=real_dis.mean().view(-1)\n",
    "                        fake_loss=fake_dis.mean().view(-1)\n",
    "                        d_loss=fake_loss-real_loss\n",
    "                        #backward and update the discriminator\n",
    "                        d_loss.backward()\n",
    "                        self.dis_opt().step()\n",
    "                    #track the Wasserstein loss\n",
    "                    w_loss.append(-d_loss.detach().item())\n",
    "                    \n",
    "                    #train the generator for one time\n",
    "                    #freeze the parameters of discirminator\n",
    "                    for p in self.D.parameters():\n",
    "                        p.requires_grad=False\n",
    "                    #neutralize the gradients\n",
    "                    self.G.zero_grad()\n",
    "                    #generate some fake imgs again\n",
    "                    noise=Variable(torch.randn(self.batch_size, self.init_channel)).cuda()\n",
    "                    fake=self.G(noise).cuda(non_blocking=True)\n",
    "                    g_loss = self.D(fake)\n",
    "                    #backward and update\n",
    "                    g_loss.backward()\n",
    "                    self.gen_opt.step()\n",
    "            if __name__ == '__main__':\n",
    "                main() \n",
    "\n",
    "            #progress check every epoch\n",
    "            #generate 100 pics from same noise\n",
    "            fake_sample = (self.G(check_noise).data + 1) / 2.0     #normalization\n",
    "            torchvision.utils.save_image(fake_sample, f'.\\\\progress_check\\\\pics\\\\epoch_{e}.jpg', nrow=10)\n",
    "            #track the Wasserstein loss\n",
    "            plt.plot(w_loss)\n",
    "            plt.savefig(f'.\\\\progress_check\\\\w_loss\\\\epoch_{e}.jpg')\n",
    "            plt.cla()\n",
    "\n",
    "            #save checkpoint every 2 epochs\n",
    "            if e % 2 == 0:\n",
    "                torch.save(self.G.state_dict(), f'.\\\\savepoint\\\\epoch_{e}_G.pth')\n",
    "                torch.save(self.D.state_dict(), f'.\\\\savepoint\\\\epoch_{e}_D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=WGAN(max_epoch=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('vits')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0336a71de4e4f396b922c50b6d8e4d55a79421c046a40c390e84d4949b69c282"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
